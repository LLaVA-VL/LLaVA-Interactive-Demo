version: "3.9"

services:

  llava:
    build:
      context: ..
      dockerfile: docker_demo/llava/Dockerfile
    # entrypoint: /bin/bash
    ports:
      - "10001:10000"
      - "40001:40000"
    volumes:
      - type: bind
        source: ..
        target: /opt/app
        read_only: false
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]
            device_ids: ["2", "3"]

  lama:
    build:
      context: ..
      dockerfile: docker_demo/lama/Dockerfile
    volumes:
      - type: bind
        source: ..
        target: /opt/app
        read_only: false
    ports:
      - "9172:9171"
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]
            device_ids: ["2", "3"]

  llava_interactive:
    build:
      context: ..
      dockerfile: docker_demo/llava_interactive/Dockerfile
    # entrypoint: /bin/bash
    volumes:
      - type: bind
        source: ..
        target: /opt/app
        read_only: false
    ports:
      - "7861:7860"
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]
            device_ids: ["2", "3"]
