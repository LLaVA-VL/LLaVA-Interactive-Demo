version: "3.9"

services:

  llava:
    build:
      context: ..
      dockerfile: docker_demo/llava/Dockerfile
    entrypoint: /bin/bash
    ports:
      - "10001:10000"
      - "40001:40000"
    volumes:
      - type: bind
        source: ..
        target: /opt/llava
        read_only: false
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]

  lama:
    build:
      context: ..
      dockerfile: docker_demo/lama/Dockerfile
    volumes:
      - type: bind
        source: ..
        target: /opt/lama
        read_only: false
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]

  llava_interactive:
    build:
      context: ..
      dockerfile: docker_demo/llava_interactive/Dockerfile
    entrypoint: /bin/bash
    volumes:
      - type: bind
        source: ..
        target: /opt/llava_int
        read_only: false
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
