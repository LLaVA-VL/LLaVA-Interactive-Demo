version: "3.9"

services:

  llava:
    build:
      context: ..
      dockerfile: docker_demo/llava/Dockerfile
    ports:
      - "10001:10000"
      - "40001:40000"
    volumes:
      - type: bind
        source: ..
        target: /opt/llava
        read_only: false
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         count: 1
    #         capabilities: [gpu]

  lama:
    build:
      context: ..
      dockerfile: docker_demo/lama/Dockerfile
    volumes:
      - type: bind
        source: ..
        target: /opt/lama
        read_only: false
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         count: 1
    #         capabilities: [gpu]

  llava_interactive:
    build:
      context: ..
      dockerfile: docker_demo/llava_interactive/Dockerfile
    volumes:
      - type: bind
        source: ..
        target: /opt/llava_int
        read_only: false
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         count: 1
    #         capabilities: [gpu]
